{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Let's find out how we did!\n",
    "\n",
    "We'll first need to load up our old classifier. Copy your .pkl files from Wednesday's folder to this one. In the example, I named my file 'D1-0.6.pkl'\n",
    "\n",
    "I'll need to copy that file to this folder. You can do this using your terminal skills from early in the course, or from the sage math cloud folder view. I've already done this for myself - and I renamed it Example-D1-0.6.pkl so that it wouldn't conflict with yours (just in case you had an 0.6 accuracy with your D1 classifier!).\n",
    "\n",
    "**Side note: Some of you ended up with 12 files for each classifier! Others have just 1. Whichever you have, you'll need to copy all files that end in .pkl and .npy over to this folder to perform the evaluation. If you got the large number of them, the terminal might be easiest**\n",
    "\n",
    "Once you've got your pickled classifier, you'll run a command like this (with the filenames changed to match your predicted accuracies):\n",
    "\n",
    "    from sklearn.externals import joblib\n",
    "    d1_classifier = joblib.load('Example-D1-0.6.pkl') \n",
    "    d2_classifier = joblib.load('Example-D2-0.9.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "d1_classifier = joblib.load('Example-D1-0.6.pkl') \n",
    "d2_classifier = joblib.load('Example-D2-0.9.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# use numpy to load our training set\n",
    "d1_validation = np.loadtxt(open(\"D1_S4.csv\", \"rb\"), delimiter=\",\")\n",
    "# features are all rows for columns before 200\n",
    "d1_validation_features = d1_validation[:,:200]\n",
    "# labels are in all rows at the 200th column\n",
    "d1_validation_labels = d1_validation[:,200]\n",
    "\n",
    "#Let's find out our accuracy on the new dataset!\n",
    "validation_score = d1_classifier.score(d1_validation_features, d1_validation_labels)\n",
    "print(\"D1 Accuracy: %0.2f\" % validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D2 Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# use numpy to load our training set\n",
    "d2_validation = np.loadtxt(open(\"D2_S4.csv\", \"rb\"), delimiter=\",\")\n",
    "# features are all rows for columns before 200\n",
    "d2_validation_features = d2_validation[:,:200]\n",
    "# labels are in all rows at the 200th column\n",
    "d2_validation_labels = d2_validation[:,200]\n",
    "\n",
    "#Let's find out our accuracy on the new dataset!\n",
    "validation_score = d2_classifier.score(d2_validation_features, d2_validation_labels)\n",
    "print(\"D2 Accuracy: %0.2f\" % validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record your results!\n",
    "\n",
    "Once you've got your accuracies in hand, head over to the reporting spreadsheet: http://bit.ly/1qwD3X0\n",
    "\n",
    "Choose an optional code name, if desired, and enter your values for D1 and D2 below those that are already entered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Q1: How did the class do? Did we generally overestimate performance, underestimate, or accurately estimate performance?_ (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Q2: Did you personally find it easier to get a good accuracy for D1 or D2? Which one required more tries to get good performance_ (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Q3: In your final classifier, what type of algorithm did you use and what parameters did you supply?_ (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Q4: What did you expect your own accuracy to be for each dataset? What did you observe? Was this surprising?_ (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Q5: What are two items of feedback that you'd like to give on this exercise?_ (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (SageMath)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
